# Distributed Systems

- [1. 基础](#1-基础)
  - [1.1. 模型](#11-模型)
  - [1.2. 副本](#12-副本)
  - [1.3. 指标](#13-指标)
- [2. 数据分布方式](#2-数据分布方式)
  - [2.1. 按哈希分布](#21-按哈希分布)
  - [2.2. 按数据范围分布](#22-按数据范围分布)
  - [2.3. 按数据量分布](#23-按数据量分布)
  - [2.4. 一致性哈希](#24-一致性哈希)
  - [2.5. 数据副本策略](#25-数据副本策略)
  - [2.6. 本地化计算](#26-本地化计算)
- [3. 基本副本协议](#3-基本副本协议)
  - [3.1. 中心化副本控制协议](#31-中心化副本控制协议)
  - [3.2. primary-secondary 协议 (primary-backup)](#32-primary-secondary-协议-primary-backup)
  - [3.3. 去中心化副本控制协议](#33-去中心化副本控制协议)
- [4. Lease 机制](#4-lease-机制)
- [5. Quorum 机制](#5-quorum-机制)
- [6. 日志技术](#6-日志技术)
- [7. 两阶段提交协议](#7-两阶段提交协议)
- [8. MVCC 分布式事务](#8-mvcc-分布式事务)
- [9. Paxos 协议](#9-paxos-协议)
- [10. CAP 理论](#10-cap-理论)

## 1. 基础

### 1.1. 模型

- 椭圆形：状态节点
- 矩形：无状态节点
- 虚线节点：宕机节点

不考虑拜占庭问题，即节点均可控

节点：可以独立运行的程序个体，进程可以是一个节点，也可以是多个

通信：通信是不可靠的

存储：有本地存储设备的节点

异常：核心问题之一

- 机器宕机
  - 大型集群一天约千分之一概率宕机
  - 宕机恢复时间一般是 24 小时，需要人工重启
  - 宕机后进入不可用状态
  - 宕机恢复：某些状态节点可以通过读取存储设备来恢复内存；无状态节点无条件恢复
- 网络异常
  - 消息丢失
    - 网络分化：图不连通
  - 消息乱序
  - 数据错误
  - 不可靠的 TCP：在 TCP 连接时会发生异常
- 数据丢失
- 无法归类的异常：磁盘 IO 慢、网络拥塞

三态：一个 RPC 执行结果有三个：成功、失败、超时

- 如果超时，可能出现 server 执行完但是没有告知 client 的情况，client 需要特殊处理
  - 通过后续读取数据来验证 RPC 是否成功
  - 通过重复执行幂等性的操作（可重试）

### 1.2. 副本

副本：分布式系统中为数据或服务提供的冗余（理论核心）

- 数据副本：在不同节点持久化同一数据
- 服务副本：多个节点提供相同的服务

副本一致性 (consistency)：分布式系统通过副本控制协议，使得各个副本的数据在一定约束条件下相同

- 强一致性：任何时刻任何用户可以读到最近的副本数据
- 单调一致性：任何时刻任何用户读到某次更新的值后，不会读到比这个值更旧的值
- 会话一致性：在一次会话中满足单调一致性
- 最终一致性：更新后副本最终能达到一致的状态，但是时间不能保障
- 弱一致性：啥都不能保证，一般不使用

### 1.3. 指标

- 性能
  - 吞吐能力：单位时间内处理的数据总量
  - 响应延迟：完成某一功能的事件
  - 并发能力：QPS
- 可用性：停服务时间除以正常服务时间，或失败次数除以成功次数。是容错能力的指标
- 可扩展性
- 一致性

## 2. 数据分布方式

### 2.1. 按哈希分布

- 将哈希值与机器建立映射关系
- 若直接计算哈希值，可扩展性不高，可以用元数据服务器管理映射关系

### 2.2. 按数据范围分布

- 哈希方式类似哈希表，范围方式类似 B+ 树，元数据服务器是 B+ 树的非叶节点
- 优点：可以拆分数据，比哈希更灵活
- 缺点：元信息复杂

### 2.3. 按数据量分布

- 将数据视为一个顺序增长的文件，并划分为多个 chunk
- 数据会均匀切分到集群中
- 缺点：元信息复杂

### 2.4. 一致性哈希

- 分布式哈希表（DHT）
- 计算哈希值，令输出值域 MAX + 1 = MIN
- 将节点随机分布到值域上，每个节点处理到下一节点上的所有数据
- 优点：增删节点比较容易
- 随机会导致分布不均匀，可以用虚节点
  - 在系统初始时创建大量虚节点，分布在值域里
  - 虚节点分配给真实节点

### 2.5. 数据副本策略

- 以机器为单位的副本
  - 几个机器的数据完全相同
  - 优点：简单
  - 缺点：恢复效率低、可扩展性差、容错低
    - 加入新机器后，全盘拷贝数据很消耗资源，需要让一个副本机器下线用于拷贝；或者让多个副本机器以限速的方式拷贝数据，会需要大量时间
    - 假设 3 个机器为一组，那么新加入 1 到 2 个机器就无法组成副本组
    - 机器宕机后组内其他机器的压力剧增
- 以数据段为单位的副本
  - 将数据拆为合理的数据段，尽量让数据段的大小在一定大小内
  - 数据段 (segment, fragment, chunk, partition)
  - 可以用哈希、数据范围、数据量、一致性哈希来管理
  - 数据恢复效率高

### 2.6. 本地化计算

- 解决大规模计算问题
- 将计算调度到存储节点上，即本地化计算

## 3. 基本副本协议

### 3.1. 中心化副本控制协议

- 由中心节点协调副本数据的更新
- 中心节点管理锁，避免并发问题
- 缺点：中心节点或其通讯异常，会失去某些服务

### 3.2. primary-secondary 协议 (primary-backup)

- 中心化
- 有两类副本：primary 副本、secondary 副本
- primary 副本一般分散到各个节点上
- 中心节点（primary 节点）维护 primary 副本
- 数据更新
  - 外部节点把更新操作发给 primary 节点
  - primary 节点进行并发控制（确定并发更新操作的先后顺序）
  - primary 节点将更新操作发送给 secondary 节点
  - primary 根据 secondary 节点的完成情况决定更新是否成功并将结果返回外部节点
  - 接力：primary 将操作发给 A，A 再把操作发给 B，……
- 数据读取 实现强一致性的一些方法
  - 只查询 primary 副本
  - 由 primary 节点控制 secondary 节点是否可用，更新不成功标记为不可用
  - Quorum 机制
- primary 副本的确定与切换
  - 当某些 primary 副本的机器异常时，需要将 secondary 副本切换到 primary 副本
  - Lease 机制确定节点状态
  - Quorum 机制确定切换的 secondary 副本
  - 可靠地发现节点异常需要约 10 秒时间，这段时间无法更新，有的甚至无法读，是 primary-secondary 协议的最大缺点
- 数据同步 primary, secondary 副本数据不一致
  - 网络分化导致更新失败
    - 回放操作日志
  - 产生脏数据
    - 设计良好的协议避免脏数据
    - 用 undo 日志
  - 新增的 secondary 副本
    - 拷贝 primary 副本数据，要求 primary 副本支持快照功能

### 3.3. 去中心化副本控制协议

- 所有节点都是对等的
- 缺点：协议过程比较复杂，不易理解，性能较低
- Paxos 是强一致性去中心化副本控制协议

## 4. Lease 机制

分布式 cache 系统

- 要求
  - 有一个中心节点，存储元数据
  - 其他节点通过访问中心节点操作元数据
  - 由于访问中心节点频繁，需要在各个节点 cache 元数据
  - 要求 cache 与中心节点数据一致
- 中心节点向各节点发送数据的同时颁发一个 lease
  - lease 有一个有效期
  - 在有效期内中心节点不会修改对应数据
- 中心节点修改数据时
  - 阻塞所有读请求（优化：可以响应但不颁发 lease）
  - 等待 lease 过期（优化：中心节点主动通知 lease 持有者放弃 lease，出现异常仍然要等待 lease 过期）

lease 机制

- 是一种承诺，例如：
  - 在 lease 有效期内不修改对应数据
  - 持有 lease 的节点才能修改数据
  - 持有 lease 的节点才是 primary 节点
- 高容错
  - 允许单向通讯（颁发者 -> 被颁发者）
  - lease 是幂等的，可以多次颁发同一 lease
  - 宕机后可以等待 lease 过期来保证 lease 正确性
  - 颁发者可以不持久化所有 lease，保存最大 lease 时间
- 颁发者有效期需要比接收者的略大，避免时钟误差

确定节点状态

- 假设 A, B, C 互为副本，A 是 primary 节点，Q 负责监测 A, B, C 状态
- A, B, C 向 Q 发送“心跳”，若 Q 未收到表示节点状态异常
- 单纯的“心跳”不能胜任
  - Q 无法得知 A 是否异常
  - A 和 Q 无法达成共识
- 解决办法：用去中心化设计或 **lease 机制**
- A, B, C 向 Q 发送“心跳”后 Q 返回一个 lease，允许节点在 lease 有效期内正常工作
- Q 给 primary 节点一个特殊 lease
- Q 希望切换 primary 只要等待 primary lease 过期即可
- 一般会多个节点互为副本，对外办法 lease

间接使用 lease：Zookeeper

## 5. Quorum 机制

write-all-read-one (WARO)

- 简单的副本控制规则
- 更新时，只有所有副本更新成功才算成功
- 更新服务无法容忍任何副本异常，但最大程度增强了读服务的可用性

Quorum 机制

- 在读写服务可用性之间做折中
- 更新操作在 N 个副本中有 W 个成功，就算更新成功
- 令 R > N - W，读 R 个副本一定能得到更新后的数据
- 仅读 R 个副本无法判断某次提交是否成功（存在脏数据）
- Quorum 机制下要满足强一致性：
  - 更新操作的版本必须严格递增
  - 客户端应不断读取副本直到有 W 个最新数据，或者最新数据个数一定不到 W 个
  - 在此要求下最多需要读 N 个副本，所以实际操作中需要其他手段

Quorum 机制选择 primary

- primary 成功更新 W 个副本后返回成功
- 读取数据有多种方法
  - 强一致性：只读 primary 副本或者 Quorum 方法
  - 会话一致性：根据之前读的版本进行选择
  - 弱一致性：任意副本
- 选择 primary 方法和 Quorum 一致，读取 R 个副本并选版本最高的副本作为 primary
  - 版本最高的虽然不是成功更新的数据，但是后续 secondary 可以和 primary 同步
  - 版本号更高的会作为脏数据移除
  - 当同步后有 W 个副本更新成功，同样可以作为更新成功的数据

## 6. 日志技术

日志在分布式中用于宕机恢复

数据库日志分为 Undo Log, Redo Log, Redo/Undo Log, No Redo/No Undo log

Redo Log

- 更新流程
  - 将更新操作追加写到日志
  - 按更新操作修改内存
  - 返回更新成功
- 宕机恢复：从头读取操作并修改内存
- Check point
  - 宕机需要恢复所有 redo，效率低
  - check point 技术将内存完整 dump 到磁盘，存到日志里
  - 宕机恢复只要找最后一个 check point 日志
  - dump 不能包含 check point 之后的操作（除非操作是幂等的）
    - 方法一：dump 停服务
    - 方法二：生成内存快照

No Undo/No Redo log

- 也叫 0/1 目录
- 一批操作，要么都生效，要么都不生效
- 目录 0 和目录 1，主记录记录当前的活动目录（0 或 1）
- 更新流程
  - 活动目录拷贝到非活动目录
  - 将更新写入日志和非活动目录
  - 原子反转主记录的 01 值

## 7. 两阶段提交协议

实现分布式事务

是一种中心化副本控制协议，一个协调者节点和 N 个参与者节点

- 阶段一：协调者询问所有参与者是否可以提交事务
- 阶段二：协调者根据投票做决定，通知所有参与者执行
- 必须所有参与者都同意

协调者流程

- 写日志 begin_commit，进入 WAIT 状态
- 发送 prepare
- 若收到 vote-abort
  - 写日志 global-abort，进入 ABORT 状态
  - 发送 global-abort
- 若收到所有 vote-commit
  - 写日志 global-commit，进入 COMMIT 状态
  - 发送 global-commit

参与者流程

- 写日志 init，进入 INIT 状态
- 接收 prepare
- 若可以提交事务
  - 写日志 ready，进入 READY 状态
  - 发送 vote-commit
  - 若收到 global-abort
    - 写日志 abort，进入 ABORT 状态
    - 发送确认消息
  - 若收到 global-commit
    - 写日志 commit，进入 COMMIT 状态
    - 发送确认消息
- 若不能提交事务
  - 写 abort，进入 ABORT 状态
  - 发送 vote-abort
  - 收到 global-abort 后确认

宕机恢复

- 协调者宕机恢复
  - WAIT，重发 prepare
  - ABORT/COMMIT，重发 global-xxx
- 参与者宕机恢复
  - INIT，等待 prepare
  - READY，重发 vote-commit
  - ABORT/COMMIT，等待 global-xxx

响应超时

- 协调者超时处理
  - WAIT，直接放弃事务，发送 global-abort
  - ABORT/COMMIT，状态处于未知
- 参与者超时处理
  - INIT，进入 ABORT 状态
  - READY，状态处于未知

缺点

- 容错差，异常时无法确定状态
- 性能差，需要两轮交互，且所有参与者都要投票

## 8. MVCC 分布式事务

实现分布式事务

多版本的并发控制，事务并行运行，可以合并。Git 使用的就是 MVCC 思想

修改时，可以拷贝后修改，也可以增量提交

- (site, var, op, oprd) 在 site 节点的 var 变量进行 op 操作，操作数为 oprd

流程

- 为每个事务分配一个递增的事务编号（版本号）
- 更新时每个结点进行更新
- 查询时读取已成功的最大事务编号，再读取数据
- 周期性对操作进行合并

## 9. Paxos 协议

强一致性、高可用的去中心化分布式协议

节点角色（一个物理节点可以同时充当三类角色）

- 提案者 Proposer 可以有多个，提出议案 value
- 批准者 Acceptor 节点完全对等，value 达到 N/2+1 Acceptor 批准就生效
- 学习者 Learner 读取被批准的 value。类似 Quorum，需要读取 N/2+1 到 N 个 Acceptor 的批准

Paxos 一轮最多批准一个 value

Proposer 流程

- 准备阶段
  - 向所有 Acceptor 发送 Prepare(b)，b=轮数
  - 如果收到 Reject(B)，设置 b=B+1 结束
- 批准阶段
  - 接收到 Promise(b, v_i) 达到 N/2+1 个
- ...

Acceptor 流程

- 接收 Prepare(b)，B 是收到的 max(b)，V 是 Acceptor 批准的 value
  - 如果 b > B，回复 Promise(b, V_B)，设置 B=b
  - 否则回复 Reject(B)
- ...

## 10. CAP 理论

CAP 是三个矛盾的属性

- Consistency 一致性：指强一致性
- Availability 可用性：异常时提供服务
- Tolerance to the partition of network 分区容忍：对网络分区的容错

CAP 理论：无法设计一个分布式协议，同时具备 CAP 三个属性

- Lease 机制：牺牲 A 得到完全的 C 和很好的 P
- Quorum 机制：CAP 都有
- 两阶段提交协议：完全的 C，AP 都很差
- Paxos 协议：完全的 C，较好的 AP
